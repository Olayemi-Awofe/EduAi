{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78fa949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "from faker import Faker\n",
    "from datetime import datetime, timedelta\n",
    "import uuid\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# --- Initialize Faker with Nigerian locale\n",
    "fake = Faker(\"en_NG\")\n",
    "\n",
    "# --- Ensure data folder exists\n",
    "os.makedirs(\"../data\", exist_ok=True)\n",
    "\n",
    "# --- Helper\n",
    "def gen_id():\n",
    "    return str(uuid.uuid4())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13671ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Generate Synthetic Schools Data\n",
    "regions = [\"North Central\", \"North East\", \"North West\", \"South East\", \"South South\", \"South West\"]\n",
    "device_types = [\"tablet\", \"laptop\", \"desktop\"]\n",
    "connectivity_levels = [\"offline\", \"intermittent\", \"online\"]\n",
    "\n",
    "# Common Nigerian school name patterns\n",
    "school_patterns = [\n",
    "    \"{} College\",\n",
    "    \"{} Grammar School\",\n",
    "    \"{} Secondary School\",\n",
    "    \"{} Academy\",\n",
    "    \"St. {} High School\",\n",
    "    \"{} Comprehensive School\",\n",
    "    \"Command Secondary School, {}\",\n",
    "    \"Federal Government College, {}\",\n",
    "    \"{} Memorial School\"\n",
    "]\n",
    "\n",
    "# Generate synthetic schools\n",
    "schools = []\n",
    "for _ in range(372):\n",
    "    name_base = fake.first_name() if random.random() > 0.4 else fake.last_name()\n",
    "    region = random.choice(regions)\n",
    "    city = fake.city()\n",
    "\n",
    "    # Select a pattern and fill with Nigerian context\n",
    "    pattern = random.choice(school_patterns)\n",
    "    school_name = pattern.format(name_base, city)\n",
    "\n",
    "    # Adjust connectivity bias (simulate rural/urban)\n",
    "    if region in [\"North East\", \"North West\"]:\n",
    "        connectivity = random.choices(connectivity_levels, weights=[0.6, 0.3, 0.1])[0]\n",
    "    elif region in [\"South East\", \"South South\"]:\n",
    "        connectivity = random.choices(connectivity_levels, weights=[0.3, 0.4, 0.3])[0]\n",
    "    else:\n",
    "        connectivity = random.choices(connectivity_levels, weights=[0.2, 0.3, 0.5])[0]\n",
    "\n",
    "    schools.append({\n",
    "        \"id\": gen_id(),\n",
    "        \"name\": school_name,\n",
    "        \"region\": region,\n",
    "        \"device_type\": random.choice(device_types),\n",
    "        \"connectivity\": connectivity\n",
    "    })\n",
    "\n",
    "df_schools = pd.DataFrame(schools)\n",
    "df_schools.to_csv(\"../data/schools.csv\", index=False)\n",
    "\n",
    "print(f\"Generated {len(df_schools)} synthetic schools.\")\n",
    "df_schools.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4e30bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_levels = [\"low\", \"medium\", \"high\"]\n",
    "\n",
    "# helper: generate Nigerian phone number\n",
    "def gen_nigerian_phone():\n",
    "    prefix = random.choice([\"080\", \"081\", \"070\", \"090\", \"091\"])\n",
    "    number = ''.join([str(random.randint(0, 9)) for _ in range(8)])\n",
    "    return f\"+234{prefix[1:]}{number}\"\n",
    "\n",
    "# language bias by region\n",
    "region_lang_map = {\n",
    "    \"North Central\": [\"English\", \"Hausa\"],\n",
    "    \"North East\": [\"English\", \"Hausa\"],\n",
    "    \"North West\": [\"English\", \"Hausa\"],\n",
    "    \"South East\": [\"English\", \"Igbo\"],\n",
    "    \"South South\": [\"English\", \"Pidgin\", \"Igbo\"],\n",
    "    \"South West\": [\"English\", \"Yoruba\"]\n",
    "}\n",
    "\n",
    "teachers = []\n",
    "for _ in range(40000):\n",
    "    school_row = df_schools.sample(1).iloc[0]\n",
    "    region = school_row[\"region\"]\n",
    "    \n",
    "    name = fake.name()\n",
    "    first = name.split()[0].lower()\n",
    "    last = name.split()[-1].lower()\n",
    "    email = f\"{first}.{last}@eduai.ng\"\n",
    "    \n",
    "    # bias tech level based on connectivity\n",
    "    if school_row[\"connectivity\"] == \"online\":\n",
    "        tech_level = random.choices(tech_levels, weights=[0.1, 0.4, 0.5])[0]\n",
    "    elif school_row[\"connectivity\"] == \"intermittent\":\n",
    "        tech_level = random.choices(tech_levels, weights=[0.3, 0.5, 0.2])[0]\n",
    "    else:\n",
    "        tech_level = random.choices(tech_levels, weights=[0.6, 0.3, 0.1])[0]\n",
    "    \n",
    "    teachers.append({\n",
    "        \"id\": gen_id(),\n",
    "        \"name\": name,\n",
    "        \"email\": email,\n",
    "        \"phone\": gen_nigerian_phone(),\n",
    "        \"school_id\": school_row[\"id\"],\n",
    "        \"languages\": json.dumps(random.sample(region_lang_map[region], k=random.randint(1, len(region_lang_map[region])))),\n",
    "        \"tech_level\": tech_level,\n",
    "        \"created_at\": fake.date_time_this_year()\n",
    "    })\n",
    "\n",
    "df_teachers = pd.DataFrame(teachers)\n",
    "df_teachers.to_csv(\"../data/teachers.csv\", index=False)\n",
    "\n",
    "print(f\"Generated {len(df_teachers)} synthetic teachers.\")\n",
    "df_teachers.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2aacbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# === setup ===\n",
    "save_dir = \"../data/curriculum_pdfs\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless=new\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "urls = {\n",
    "    \"pri1-3\": \"https://nerdc.gov.ng/content_manager/pri1-3.html\",\n",
    "    \"pri4-6\": \"https://nerdc.gov.ng/content_manager/pri4-6.html\",\n",
    "    \"jss1-3\": \"https://nerdc.gov.ng/content_manager/jss1-3.html\",\n",
    "    \"aep\": \"https://nerdc.gov.ng/content_manager/aep.html\",\n",
    "}\n",
    "base_url = \"https://nerdc.gov.ng/content_manager/\"\n",
    "\n",
    "def download_pdf(url, filename):\n",
    "    path = os.path.join(save_dir, filename)\n",
    "    try:\n",
    "        r = requests.get(url, stream=True, timeout=60)\n",
    "        r.raise_for_status()\n",
    "        with open(path, \"wb\") as f:\n",
    "            for chunk in r.iter_content(1024):\n",
    "                f.write(chunk)\n",
    "        print(f\"Downloaded {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed {filename}: {e}\")\n",
    "\n",
    "for key, page in urls.items():\n",
    "    print(f\"\\n Visiting {page}\")\n",
    "    driver.get(page)\n",
    "    time.sleep(3)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    links = []\n",
    "\n",
    "    # Find any embedded/view links\n",
    "    for a in soup.find_all(\"a\", href=True):\n",
    "        href = a[\"href\"]\n",
    "        if href.lower().endswith(\".pdf\"):\n",
    "            links.append(urljoin(base_url, href))\n",
    "        elif \"view_\" in href:\n",
    "            view_page = urljoin(base_url, href)\n",
    "            driver.get(view_page)\n",
    "            try:\n",
    "                iframe = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.TAG_NAME, \"iframe\"))\n",
    "                )\n",
    "                pdf_url = iframe.get_attribute(\"src\")\n",
    "                if pdf_url:\n",
    "                    pdf_full = urljoin(base_url, pdf_url)\n",
    "                    links.append(pdf_full)\n",
    "                    print(f\"Found embedded PDF → {pdf_full.split('/')[-1]}\")\n",
    "            except:\n",
    "                print(f\"Couldn’t read iframe from {view_page}\")\n",
    "            driver.back()\n",
    "            time.sleep(2)\n",
    "\n",
    "    print(f\"Found {len(links)} PDF(s) on {page}\")\n",
    "\n",
    "    for link in links:\n",
    "        filename = os.path.basename(link.split(\"?pdf=\")[-1])\n",
    "        if not filename.lower().endswith(\".pdf\"):\n",
    "            filename += \".pdf\"\n",
    "        download_pdf(link, f\"{key}_{filename}\")\n",
    "\n",
    "driver.quit()\n",
    "print(\"\\n Done — check curriculum_pdfs folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aab67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Update this path to your Tesseract installation\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "pdf_folder = \"curriculum_pdfs\"\n",
    "rows = []\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    pages = convert_from_path(pdf_path, dpi=300)\n",
    "    text = \"\"\n",
    "    for page in pages:\n",
    "        text += pytesseract.image_to_string(page, lang='eng') + \"\\n\"\n",
    "    return text\n",
    "\n",
    "def extract_curriculum_info(text, filename):\n",
    "    doc = nlp(text)\n",
    "    subject = re.search(r\"(English|Mathematics|Basic Science|Social Studies|French|Igbo|Yoruba|Hausa|Arabic|Islamic|Prevocational|Civic|History)\", text, re.I)\n",
    "    level = re.search(r\"(Primary\\s?\\d?[-–]?\\d?|JSS\\s?\\d?[-–]?\\d?|AEP)\", text, re.I)\n",
    "    subject = subject.group(0) if subject else os.path.splitext(filename)[0]\n",
    "    level = level.group(0) if level else \"Unknown\"\n",
    "    topics = re.findall(r\"(?:Topic|Unit)\\s*\\d*[:\\-]?\\s*(.+)\", text, re.I)\n",
    "    subtopics = re.findall(r\"(?:Sub-Topic|Subtopic)\\s*\\d*[:\\-]?\\s*(.+)\", text, re.I)\n",
    "    objectives = re.findall(r\"(?:Objective|Learning Outcome|Aim)\\s*[:\\-]?\\s*(.+)\", text, re.I)\n",
    "\n",
    "    if not topics:\n",
    "        chunks = [sent.text for sent in doc.sents if len(sent.text.split()) > 3]\n",
    "        topics = chunks[:min(len(chunks), 5)]\n",
    "\n",
    "    for i, t in enumerate(topics):\n",
    "        rows.append({\n",
    "            \"Level\": level,\n",
    "            \"Subject\": subject,\n",
    "            \"Topic\": t.strip(),\n",
    "            \"Subtopic\": subtopics[i] if i < len(subtopics) else \"\",\n",
    "            \"Objective\": objectives[i] if i < len(objectives) else \"\"\n",
    "        })\n",
    "\n",
    "for pdf in tqdm([f for f in os.listdir(pdf_folder) if f.endswith(\".pdf\")]):\n",
    "    text = extract_text_from_pdf(os.path.join(pdf_folder, pdf))\n",
    "    extract_curriculum_info(text, pdf)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(\"curriculum_units.csv\", index=False)\n",
    "print(\"Done — curriculum_units.csv created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8025f8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import uuid\n",
    "import re\n",
    "\n",
    "# --- File path\n",
    "file_path = \"curriculum.txt\"\n",
    "\n",
    "# --- Helper function to generate unique IDs\n",
    "def gen_id():\n",
    "    return str(uuid.uuid4())\n",
    "\n",
    "# --- Read the text file\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "curriculum_units = []\n",
    "\n",
    "# --- Define levels\n",
    "levels = {\n",
    "    \"Primary 1-3\": r\"Primary 1-3 Basic Education Subject List(.*?)(?=Primary 4-6|JSS|SSS|$)\",\n",
    "    \"Primary 4-6\": r\"Primary 4-6(.*?)(?=Junior Secondary School|JSS|SSS|$)\",\n",
    "    \"JSS 1-3\": r\"Junior Secondary School 1(.*?)(?=Senior Secondary School|SSS|$)\",\n",
    "    \"SSS\": r\"Senior Secondary School Subject List(.*)$\"\n",
    "}\n",
    "\n",
    "# --- Extract subjects for each level\n",
    "for level_name, pattern in levels.items():\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        content = match.group(1)\n",
    "        # Split by line numbers or bullet points\n",
    "        lines = re.split(r\"\\n\\d+\\s|•\\s|[0-9]+\\.\\s\", content)\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                curriculum_units.append({\n",
    "                    \"id\": gen_id(),\n",
    "                    \"title\": line[:100],  # limit title length\n",
    "                    \"subject\": line.split()[0] if len(line.split())>0 else line,  # first word as subject\n",
    "                    \"grade_level\": level_name,\n",
    "                    \"source_doc\": file_path,\n",
    "                    \"canonical_learning_outcomes\": json.dumps({\"outcomes\": []})\n",
    "                })\n",
    "\n",
    "# --- Convert to DataFrame\n",
    "df_curriculum = pd.DataFrame(curriculum_units)\n",
    "\n",
    "# --- Save CSV\n",
    "df_curriculum.to_csv(r\"C:\\Users\\HP\\Desktop\\EduAi\\data\\curriculum_units.csv\", index=False)\n",
    "df_curriculum.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066626a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = r\"C:\\Users\\HP\\Desktop\\EduAi\\data\\curriculum_units.csv\"\n",
    "\n",
    "# Use latin-1 to handle Windows encoding\n",
    "df = pd.read_csv(csv_path, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1281d3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_id():\n",
    "    return str(uuid.uuid4())\n",
    "\n",
    "df[\"id\"] = df[\"id\"].fillna(\"\").astype(str)\n",
    "df[\"id\"] = df[\"id\"].apply(lambda x: x if x.strip() != \"\" else gen_id())\n",
    "\n",
    "if df[\"id\"].duplicated().any():\n",
    "    seen = set()\n",
    "    new_ids = []\n",
    "    for val in df[\"id\"]:\n",
    "        if val in seen:\n",
    "            new_ids.append(gen_id())\n",
    "        else:\n",
    "            new_ids.append(val)\n",
    "            seen.add(val)\n",
    "    df[\"id\"] = new_ids\n",
    "\n",
    "df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "print(\"All rows now have ID populated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6869f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_curriculum = pd.read_csv(r\"C:\\Users\\HP\\Desktop\\EduAi\\data\\curriculum_units.csv\", encoding=\"utf-8\")\n",
    "df_teachers = pd.read_csv(r\"C:\\Users\\HP\\Desktop\\EduAi\\data\\teachers.csv\", encoding=\"utf-8\")\n",
    "\n",
    "# Function to generate uniqu IDs\n",
    "def gen_id():\n",
    "    return str(uuid.uuid4())\n",
    "\n",
    "# Generate lessons\n",
    "lessons = []\n",
    "for _ in range(2800): \n",
    "    lessons.append({\n",
    "        \"id\": gen_id(),\n",
    "        \"curriculum_unit_id\": random.choice(df_curriculum[\"id\"]),\n",
    "        \"teacher_id\": random.choice(df_teachers[\"id\"]),\n",
    "        \"content\": json.dumps({\"body\": fake.paragraph(nb_sentences=4)}),\n",
    "        \"assets\": json.dumps({\"images\": [fake.image_url() for _ in range(2)]}),\n",
    "        \"lesson_metadata\": json.dumps({\n",
    "            \"duration\": f\"{random.choice([30, 45, 60])} mins\",\n",
    "            \"objectives\": fake.sentences(nb=random.randint(1,3))\n",
    "        }),\n",
    "        \"generated_at\": fake.date_time_this_year().isoformat()\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_lessons = pd.DataFrame(lessons)\n",
    "\n",
    "# Save to CSV\n",
    "df_lessons.to_csv(r\"C:\\Users\\HP\\Desktop\\EduAi\\data\\lessons.csv\", index=False)\n",
    "\n",
    "# Quick check\n",
    "df_lessons.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59250e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load question bank\n",
    "json_path = r\"C:\\Users\\HP\\Desktop\\EduAi\\notebooks\\questions_bank.json\"\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    questions_bank = json.load(f)\n",
    "\n",
    "# Generate assessments\n",
    "assessments = []\n",
    "\n",
    "for _ in range(3896):  # total assessments\n",
    "    lesson = random.choice(df_lessons.to_dict(\"records\"))\n",
    "    # Try to pick a subject from lesson if available, otherwise random subject\n",
    "    subject = lesson.get(\"subject\") or random.choice(list(questions_bank.keys()))\n",
    "    question_pool = questions_bank.get(subject, [])\n",
    "\n",
    "    if not question_pool:  # fallback in case subject not in bank\n",
    "        continue\n",
    "\n",
    "    num_questions = random.randint(2, 4)\n",
    "    sampled = random.sample(question_pool, min(num_questions, len(question_pool)))\n",
    "\n",
    "    assessments.append({\n",
    "        \"id\": gen_id(),\n",
    "        \"lesson_id\": lesson[\"id\"],\n",
    "        \"items\": json.dumps({\n",
    "            \"questions\": [q[\"question\"] for q in sampled],\n",
    "            \"answers\": [q[\"answer\"] for q in sampled]\n",
    "        })\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_assessments = pd.DataFrame(assessments)\n",
    "\n",
    "# Save to CSV\n",
    "df_assessments.to_csv(r\"C:\\Users\\HP\\Desktop\\EduAi\\data\\assessments.csv\", index=False)\n",
    "\n",
    "# Quick check\n",
    "df_assessments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ba8012",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = [\"AI basics\", \"Python for teaching\", \"Robotics intro\", \"Lesson design\", \"STEM integration\", \"Excel for educators\", \"Words\", \"PowerPoint\", \"Google Classroom\", \"Digital literacy\"]\n",
    "\n",
    "progress = []\n",
    "for _ in range(13200):\n",
    "    progress.append({\n",
    "        \"id\": gen_id(),\n",
    "        \"teacher_id\": random.choice(df_teachers[\"id\"]),\n",
    "        \"skill\": random.choice(skills),\n",
    "        \"level\": random.choice([\"beginner\", \"intermediate\", \"advanced\"]),\n",
    "        \"last_practiced\": fake.date_time_this_year()\n",
    "    })\n",
    "\n",
    "df_progress = pd.DataFrame(progress)\n",
    "df_progress.to_csv(r\"C:\\Users\\HP\\Desktop\\EduAi\\data\\teacher_progress.csv\", index=False)\n",
    "df_progress.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c4ad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [\"generate_lesson\", \"refine_prompt\", \"download_pdf\", \"login\", \"logout\"]\n",
    "\n",
    "# Generate audit logs\n",
    "audit = []\n",
    "for _ in range(11780):\n",
    "    audit.append({\n",
    "        \"id\": gen_id(),\n",
    "        \"user_id\": random.choice(df_teachers[\"id\"]),\n",
    "        \"action\": random.choice(actions),\n",
    "        \"prompt_hash\": fake.sha1(),\n",
    "        \"model_used\": random.choice([\"gpt-4o-mini\", \"gpt-4\", \"mistral\", \"claude\"]),\n",
    "        \"output_ref\": fake.uri(),\n",
    "        \"timestamp\": fake.date_time_this_year()\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_audit = pd.DataFrame(audit)\n",
    "\n",
    "# Save to CSV\n",
    "df_audit.to_csv(r\"C:\\Users\\HP\\Desktop\\EduAi\\data\\audit_log.csv\", index=False)\n",
    "\n",
    "# Quick check\n",
    "df_audit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29f4c798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Added 'chapter_reached' and 'total_chapters' columns.\n"
     ]
    }
   ],
   "source": [
    "# --- Connect to DB\n",
    "db_path = r\"C:\\Users\\HP\\Desktop\\EduAi\\db\\edu_ai.db\"\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# 1. Add new columns if they don't exist\n",
    "try:\n",
    "    cursor.execute(\"ALTER TABLE teacher_progress ADD COLUMN chapter_reached INTEGER;\")\n",
    "    cursor.execute(\"ALTER TABLE teacher_progress ADD COLUMN total_chapters INTEGER;\")\n",
    "    print(\"Added 'chapter_reached' and 'total_chapters' columns.\")\n",
    "except Exception as e:\n",
    "    print(\"Columns may already exist:\", e)\n",
    "\n",
    "# 2. Backfill data with random values\n",
    "for row_id in cursor.execute(\"SELECT id FROM teacher_progress\").fetchall():\n",
    "    total = random.randint(5, 15)\n",
    "    reached = random.randint(1, total)\n",
    "    cursor.execute(\"\"\"\n",
    "        UPDATE teacher_progress\n",
    "        SET total_chapters = ?, chapter_reached = ?\n",
    "        WHERE id = ?;\n",
    "    \"\"\", (total, reached, row_id[0]))\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a995b8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>teacher_id</th>\n",
       "      <th>skill</th>\n",
       "      <th>level</th>\n",
       "      <th>last_practiced</th>\n",
       "      <th>chapter_reached</th>\n",
       "      <th>total_chapters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c7626b77-86be-4a78-8f42-754ec6736e21</td>\n",
       "      <td>e59fc076-f6f8-4b74-b556-9e3ec0d2e336</td>\n",
       "      <td>Lesson design</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>2025-09-22 16:24:59</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>289dcf8a-d7ac-412a-9b95-cd201e3af877</td>\n",
       "      <td>0e97f849-b145-4580-924e-51dbb636ff84</td>\n",
       "      <td>PowerPoint</td>\n",
       "      <td>beginner</td>\n",
       "      <td>2025-09-08 00:25:56</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>836765fc-751b-464b-aab6-0ff9645f88fa</td>\n",
       "      <td>51b926ab-0081-4cc9-83c9-f5b08edd4960</td>\n",
       "      <td>Words</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>2025-07-18 17:04:04</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f7b98dbc-f14a-4d5b-a142-d8dd0498ba0b</td>\n",
       "      <td>a111e987-763c-460a-9875-767c06987111</td>\n",
       "      <td>Excel for educators</td>\n",
       "      <td>advanced</td>\n",
       "      <td>2025-08-29 22:40:41</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3877b5ba-0335-4c1c-8495-3000bb447421</td>\n",
       "      <td>2c4917f6-eb1d-4c4b-98e6-0f8808b862c2</td>\n",
       "      <td>PowerPoint</td>\n",
       "      <td>intermediate</td>\n",
       "      <td>2025-07-03 19:35:49</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id                            teacher_id  \\\n",
       "0  c7626b77-86be-4a78-8f42-754ec6736e21  e59fc076-f6f8-4b74-b556-9e3ec0d2e336   \n",
       "1  289dcf8a-d7ac-412a-9b95-cd201e3af877  0e97f849-b145-4580-924e-51dbb636ff84   \n",
       "2  836765fc-751b-464b-aab6-0ff9645f88fa  51b926ab-0081-4cc9-83c9-f5b08edd4960   \n",
       "3  f7b98dbc-f14a-4d5b-a142-d8dd0498ba0b  a111e987-763c-460a-9875-767c06987111   \n",
       "4  3877b5ba-0335-4c1c-8495-3000bb447421  2c4917f6-eb1d-4c4b-98e6-0f8808b862c2   \n",
       "\n",
       "                 skill         level       last_practiced  chapter_reached  \\\n",
       "0        Lesson design  intermediate  2025-09-22 16:24:59                7   \n",
       "1           PowerPoint      beginner  2025-09-08 00:25:56                3   \n",
       "2                Words  intermediate  2025-07-18 17:04:04                9   \n",
       "3  Excel for educators      advanced  2025-08-29 22:40:41                5   \n",
       "4           PowerPoint  intermediate  2025-07-03 19:35:49                7   \n",
       "\n",
       "   total_chapters  \n",
       "0              11  \n",
       "1               9  \n",
       "2              14  \n",
       "3              13  \n",
       "4               7  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the update\n",
    "df_test = pd.read_sql_query(\"SELECT * FROM teacher_progress LIMIT 5;\", conn)\n",
    "df_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
